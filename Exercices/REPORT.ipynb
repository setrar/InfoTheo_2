{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "597368ac-24e9-41e7-a8d3-f46cea4f673a",
      "metadata": {},
      "source": [
        "| Practice Exercises for Information-Theory 2 |\n",
        "|:-:|\n",
        "| Professor Petros Elia, elia@eurecom.fr | \n",
        "| February 9th, 2024 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9140a845-e72a-497b-a3e5-baf4a8f7da30",
      "metadata": {},
      "source": [
        "# Let $\\mathbb{F}_n^2$ be the set of all binary vectors, and let $\\mathcal{A_{\\epsilon}^n}$ be the set of typical sequences based on non-trivial distribution. Which is true below?\n",
        "- a) $Prob(\\mathcal{A_{\\epsilon}^n}) \\approx 1$ or b) $Prob(\\mathcal{A_{\\epsilon}^n}) \\ll 1$\n",
        "- c) $| \\mathcal{A_{\\epsilon}^n} | \\ll 2^n$ or d) $|\\mathcal{A_{\\epsilon}^n}| \\approx 1$ ?\n",
        "\n",
        "In the above, choose a) or b) and then choose c) or d). Justify."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c8541f-4310-4fb9-99b3-fc13946d5a9e",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "For this problem, we are dealing with the typical set $\\mathcal{A_{\\epsilon}^n}$ from information theory, specifically from the context of the **Asymptotic Equipartition Property (AEP)**.\n",
        "\n",
        "#### Part 1: Probability of the typical set\n",
        "The typical set $\\mathcal{A_{\\epsilon}^n}$ is defined such that most of the probability mass is concentrated there as $n$ becomes large. Based on the AEP, for large $n$, the probability of drawing a sequence from the typical set approaches 1:\n",
        "\n",
        "$P(\\mathcal{A_{\\epsilon}^n}) \\approx 1$\n",
        "\n",
        "This corresponds to option **a)**. Therefore, **a)** is correct.\n",
        "\n",
        "#### Part 2: Size of the typical set\n",
        "Now, let's consider the size of the typical set. For a random variable with entropy $H(X)$, the number of typical sequences is roughly $2^{nH(X)}$. Since $H(X) < \\log_2(2^n) = n$ (entropy is always less than or equal to $n$ for a binary source), we conclude that the size of the typical set is much smaller than the total number of sequences in $\\mathbb{F}_n^2$, which is $2^n$.\n",
        "\n",
        "Therefore:\n",
        "\n",
        "$|\\mathcal{A_{\\epsilon}^n}| \\ll 2^n$\n",
        "\n",
        "This corresponds to option **c)**.\n",
        "\n",
        "#### Conclusion:\n",
        "The correct answers are:\n",
        "- **a)**: $P(\\mathcal{A_{\\epsilon}^n}) \\approx 1$\n",
        "- **c)**: $|\\mathcal{A_{\\epsilon}^n}| \\ll 2^n$ \n",
        "\n",
        "These are consistent with the properties of the typical set in information theory."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aadcd3f6-f4c2-4828-b342-c8686fad4d5f",
      "metadata": {},
      "source": [
        "# In a communication setting where $X$ defines the input and $Y$ defines the output, what is the connection between the mutual information $I (X ; Y )$ and the channel capacity? Offer some intuition as well as review the proof."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ca891b-f2eb-4168-a880-8f3e30f9e237",
      "metadata": {},
      "source": [
        "---\n",
        "#### Connection Between Mutual Information $I(X; Y)$ and Channel Capacity $C$\n",
        "\n",
        "1. **Definitions**:\n",
        "   - **Mutual Information**: $I(X; Y) = H(X) - H(X | Y)$\n",
        "     - Measures the amount of information that $Y$ reveals about $X$.\n",
        "   - **Channel Capacity**: $C = \\max_{p(x)} I(X; Y)$\n",
        "     - The maximum rate at which information can be reliably transmitted over a channel.\n",
        "\n",
        "2. **Intuition**:\n",
        "   - $I(X; Y)$ quantifies the reduction in uncertainty about $X$ when $Y$ is known.\n",
        "   - $C$ is achieved by selecting the input distribution $p(x)$ that maximizes $I(X; Y)$.\n",
        "\n",
        "3. **Key Steps in the Proof**:\n",
        "   - **Channel Model**: For a discrete memoryless channel, characterized by transition probabilities $P(y|x)$.\n",
        "   - **Maximization**: Find $C$ by maximizing $I(X; Y)$ over all input distributions.\n",
        "   - **Achievability**: Shannon's theorem shows that $C$ can be approached with specific coding strategies, ensuring low error rates.\n",
        "\n",
        "4. **Conclusion**:\n",
        "   - The relationship between $I(X; Y)$ and $C$ is crucial for designing efficient communication systems, where maximizing mutual information leads to reliable transmission rates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d2b09f-c46a-4c2b-bc80-7135584ca43a",
      "metadata": {},
      "source": [
        "# Consider a multiple-input multiple-output (MIMO) channel with 2 transmit antennas, 3 receive antennas, and random fading where you can only encode over 1 coherence period. Assume Rayleigh fading where the fading coefficients are iid and distributed as complex-normal random variables with zero mean and unit variance. What is approximately the probability of error if the signal-to-noise ratio is approximately SNR= 10000?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffeb2651-471c-4f38-8352-109b8b70a956",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Let's break down and analyze the problem step-by-step to find the approximate probability of error.\n",
        "\n",
        "#### **Step 1: Channel Setup and Assumptions**\n",
        "- **MIMO Setup:** 2 transmit antennas, 3 receive antennas.\n",
        "- **Rayleigh Fading:** Each channel coefficient $h_{ij}$ is distributed as $\\mathcal{CN}(0, 1)$ (complex Gaussian with zero mean and unit variance).\n",
        "- **Signal-to-noise ratio (SNR):** $\\text{SNR} = 10,000$ (i.e., $40 \\, \\text{dB}$).\n",
        "\n",
        "#### **Step 2: Error Analysis**\n",
        "- For high SNR scenarios, the probability of error is dominated by the diversity order of the MIMO system.\n",
        "- **Diversity Order:**  \n",
        "  In MIMO systems, the diversity order is given by the product of the number of transmit and receive antennas, $D = N_t \\times N_r$. Here:\n",
        "$D = 2 \\times 3 = 6$\n",
        "\n",
        "- The probability of error in MIMO Rayleigh fading channels can be approximated at high SNR using the formula:\n",
        "$P_e \\approx \\left( \\frac{1}{\\text{SNR}} \\right)^D$\n",
        "\n",
        "#### **Step 3: Compute the Probability of Error**\n",
        "Given $\\text{SNR} = 10,000 = 10^4$ and $D = 6$:\n",
        "$P_e \\approx \\left( \\frac{1}{10^4} \\right)^6 = 10^{-24}$\n",
        "\n",
        "#### **Step 4: Interpretation**\n",
        "- The error probability is exceedingly small ($10^{-24}$), which is expected for a system with high diversity and very high SNR.\n",
        "\n",
        "This result demonstrates how increasing both SNR and diversity significantly reduces the error probability in MIMO systems under Rayleigh fading."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef062ff4-0557-4fd2-903f-59749346862a",
      "metadata": {},
      "source": [
        "# Can you provide real-life settings (emphasis on the channel behavior) where we must use the metric of ergodic capacity, of $\\epsilon$-outage capacity, and of AWGN capacity?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d74cfd5e-d921-450c-9251-cbca658fab12",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Capacity Metrics and Channel Settings**\n",
        "\n",
        "| **Metric**            | **Channel Behavior**         | **Real-Life Example**                  |\n",
        "|------------------------|------------------------------|-----------------------------------------|\n",
        "| **Ergodic Capacity**   | Rapid, time-varying fading   | Mobile broadband (e.g., 4G/5G urban)    |\n",
        "| **$\\epsilon$-Outage Capacity** | Deep fades, unreliable links | Vehicle-to-Everything (V2X) safety       |\n",
        "| **AWGN Capacity**      | Stable, no fading            | Satellite communication                 |\n",
        "\n",
        "- **Ergodic:** Used when channel variations average out over time.  \n",
        "- **Outage:** Used where reliability is crucial despite deep fades.  \n",
        "- **AWGN:** Used when channel is static and predictable.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2c2691-70d7-43b7-9614-708682d5d6c2",
      "metadata": {},
      "source": [
        "# Explain the difference between the orthogonal and the non-orthogonal multiple-access settings. What are the practical consequences on the receiver?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2fae97-5ba3-4bb4-b75e-167ffcb82f3b",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Orthogonal vs Non-Orthogonal Multiple Access**\n",
        "\n",
        "| **Feature**            | **Orthogonal Access (OMA)**              | **Non-Orthogonal Access (NOMA)**             |\n",
        "|------------------------|-------------------------------------------|-----------------------------------------------|\n",
        "| **Resource Allocation**| Separate, non-overlapping (e.g., time, freq.) | Shared resources (e.g., same time & freq.)   |\n",
        "| **Interference**       | No user-to-user interference              | Interference between users                    |\n",
        "| **Receiver Complexity**| Low (no interference cancellation)        | High (requires SIC or similar techniques)     |\n",
        "| **Resource Efficiency**| Lower (may have idle resources)           | Higher (better resource utilization)          |\n",
        "| **Example**            | OFDMA (e.g., 4G LTE)                      | NOMA (e.g., 5G)                               |\n",
        "\n",
        "- **OMA:** Simple receivers but lower efficiency.  \n",
        "- **NOMA:** Efficient but complex receivers due to interference management."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff823d67-9bca-4a86-8101-153a78668db0",
      "metadata": {},
      "source": [
        "# Consider a multi-antenna communication setting. Let us be able to send 10 different 64-QAM symbols in 4 channel uses. What is the rate of communication in bits per channel use (bpcu)? What would the constellation size be if, under the same conditions, we wished to double the rate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6dd6c3-d360-496c-89fb-d5d098134540",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Step 1: Calculate the rate in bits per channel use (bpcu)**  \n",
        "Given:\n",
        "- **Symbols:** 10 symbols transmitted  \n",
        "- **Constellation:** 64-QAM (each symbol represents $\\log_2(64) = 6$ bits)  \n",
        "- **Channel uses:** 4  \n",
        "\n",
        "#### **Rate Calculation**  \n",
        "The total number of bits sent:\n",
        "$\\text{Bits sent} = 10 \\times 6 = 60 \\text{ bits}$\n",
        "\n",
        "The rate in bits per channel use (bpcu) is:\n",
        "$R = \\frac{\\text{Bits sent}}{\\text{Channel uses}} = \\frac{60}{4} = 15 \\, \\text{bpcu}$\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2: Doubling the rate**  \n",
        "We want to double the rate to:\n",
        "$R' = 2 \\times 15 = 30 \\, \\text{bpcu}$\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3: Find the new constellation size**  \n",
        "Let $M'$ be the new constellation size. We still send **10 symbols** in **4 channel uses**, so the required bits per symbol are:\n",
        "$\\text{Bits per symbol} = \\frac{30 \\, \\text{bpcu} \\times 4 \\, \\text{channel uses}}{10 \\, \\text{symbols}} = 12 \\, \\text{bits per symbol}$\n",
        "\n",
        "The constellation size is:\n",
        "$M' = 2^{12} = 4096$\n",
        "\n",
        "---\n",
        "\n",
        "### **Final Answer**  \n",
        "- **Current rate:** 15 bpcu  \n",
        "- **New constellation size for doubled rate:** $M' = 4096$-QAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86eeef4-9099-4cba-bb30-6e6d8a34669e",
      "metadata": {},
      "source": [
        "# Consider gathering statistics on the frequency with which different 6-tuples of letters appear in the English language. Argue what is (the order of, i.e., approximately) the amount of data that you\u2019d need to gather such statistics that are reliable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e739f5-5917-4e10-bf29-6f7229b67913",
      "metadata": {},
      "source": [
        "---\n",
        "#### **Step 1: Number of Possible 6-tuples**  \n",
        "For a 6-tuple of letters, assuming there are 26 letters in the English alphabet, the total number of possible combinations is:\n",
        "$N = 26^6 = 308,915,776$\n",
        "\n",
        "#### **Step 2: Statistical Reliability**  \n",
        "To gather reliable statistics, each 6-tuple should ideally appear multiple times (e.g., at least **10 times** for reasonable statistical confidence). However, most 6-tuples will occur rarely, as English has strong constraints based on word structure, making many tuples highly improbable.\n",
        "\n",
        "Let $f_{\\text{min}}$ denote the frequency of the **least common relevant tuple**.  \n",
        "In natural English text:\n",
        "- Common 6-tuples (e.g., \"thatis\", \"should\") occur frequently.\n",
        "- Rare ones (e.g., \"qzxvwy\") may rarely appear, if ever.\n",
        "\n",
        "To approximate data needs:\n",
        "- Suppose **$N_{\\text{effective}}$**, the number of realistically occurring 6-tuples, is approximately $10^6$ based on linguistic constraints.\n",
        "- We want **at least 10 occurrences** of each relevant tuple:\n",
        "$\\text{Required data size} \\approx 10 \\times N_{\\text{effective}} = 10^7 \\text{ tuples}$\n",
        "\n",
        "#### **Step 3: Data in English Text**  \n",
        "Assuming about **5 characters per word** on average (including spaces/punctuation):\n",
        "$\\text{Words required} \\approx 2 \\times 10^6 \\, \\text{words}$\n",
        "\n",
        "In terms of text:\n",
        "- Average English text has ~250 words per page.\n",
        "- Data requirement = $\\frac{2 \\times 10^6 \\, \\text{words}}{250 \\, \\text{words per page}} \\approx 8000 \\, \\text{pages}$.\n",
        "\n",
        "#### **Summary**\n",
        "- **Order of data required:** $\\sim10^7$ 6-tuples or $\\sim2$ million words of English text (~8000 pages).  \n",
        "- This ensures each 6-tuple appears enough times to gather reliable statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd3bf77-c967-4846-9d9b-97791bf57a05",
      "metadata": {},
      "source": [
        "# Consider the 3-user broadcast channel, with links $|h_1|^2 = 0.7,|h_2|^2 = 0.4,|h_3|^2 = 0.2$, having also a unit power noise at the receivers. Let Pk be the power of the signal meant for user k, and let $P_1 = 10,P_2 = 5$ and $P_3 = 1$. Describe the capacity region, and how this is achieved by describing the method of decoding."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d77062-9ddb-4b9d-93c5-a75e033f78c3",
      "metadata": {},
      "source": [
        "### **Capacity Region of 3-User Broadcast Channel**\n",
        "\n",
        "| **User**   | **Channel Gain** $|h_k|^2$ | **Power** $P_k$ | **SNR** $\\frac{|h_k|^2 P_k}{1}$ | **Achievable Rate** $R_k$ |\n",
        "|------------|----------------------|-----------|------------------------|--------------------------------------|\n",
        "| User 1     | 0.7                  | 10        | 7                      | $\\log_2(1 + 7) \\approx 3 \\, \\text{bpcu}$ |\n",
        "| User 2     | 0.4                  | 5         | 2                      | $\\log_2(1 + 2) \\approx 1.585 \\, \\text{bpcu}$ |\n",
        "| User 3     | 0.2                  | 1         | 0.2                    | $\\log_2(1 + 0.2) \\approx 0.263 \\, \\text{bpcu}$ |\n",
        "\n",
        "---\n",
        "\n",
        "### **Method of Achieving Capacity**\n",
        "1. **Superposition Coding:** The transmitter sends a superposition of all user signals.\n",
        "2. **Successive Interference Cancellation (SIC):**\n",
        "   - **User 1:** Decodes $X_3$, then $X_2$, and finally $X_1$.\n",
        "   - **User 2:** Decodes $X_3$, removes it, and then decodes $X_2$.\n",
        "   - **User 3:** Directly decodes $X_3$ with no interference removal. \n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "- **Achievable rates:** $R_1 \\approx 3$, $R_2 \\approx 1.585$, $R_3 \\approx 0.263$ bpcu.  \n",
        "- The capacity region is achieved through superposition coding and SIC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a046b6-380b-40c8-b2df-9c87e672e16c",
      "metadata": {},
      "source": [
        "# What is approximately the doubling rate in a horse race, if your starting bet is 10 euros, you always bet your accumulated funds, and your income in 10 bets is equal to 20000 euros?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6a5513f-50ba-4fe8-890f-2a258977b948",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#### **Step 1: Define Variables**\n",
        "- Starting bet: $B_0 = 10 \\, \\text{euros}$\n",
        "- Final accumulated income: $B_{10} = 20,000 \\, \\text{euros}$\n",
        "- We bet our entire funds each time, so the capital grows by a factor per bet.\n",
        "  \n",
        "Let the growth factor per bet be $r$. The capital after $n$ bets is:\n",
        "$B_n = B_0 \\cdot r^n$\n",
        "\n",
        "For $n = 10$:\n",
        "$B_{10} = 10 \\cdot r^{10} = 20,000$\n",
        "\n",
        "#### **Step 2: Solve for $r$**\n",
        "$r^{10} = \\frac{20,000}{10} = 2,000$\n",
        "$r = (2,000)^{1/10} \\approx 3.162$\n",
        "\n",
        "#### **Step 3: Calculate Doubling Rate**\n",
        "The doubling rate refers to how many bets it takes for the capital to double. We need to solve for $n$ such that:\n",
        "$2 = r^n$\n",
        "$n = \\frac{\\log(2)}{\\log(r)} = \\frac{\\log(2)}{\\log(3.162)}$\n",
        "\n",
        "Calculating:\n",
        "$n \\approx \\frac{0.3010}{0.4997} \\approx 0.602 \\, \\text{bets}$\n",
        "\n",
        "#### **Final Answer**\n",
        "- The approximate doubling rate is **0.6 bets**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ec3a47b-f3f0-400d-8627-69d14044ce54",
      "metadata": {},
      "source": [
        "# Derive the Kullback-Leibler distance between two distributions: the first is the fair dice distribution, and the other is the distribution where the equiprobable outcomes 1,2,3 have a double probability than equiprobable outcomes 4,5,6."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ac4059a-52a5-431d-8403-0f069b99e777",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#### **Step 1: Define the two distributions**\n",
        "\n",
        "1. **Fair dice distribution:**  \n",
        "$P(i) = \\frac{1}{6}, \\quad i \\in \\{1, 2, 3, 4, 5, 6\\}$\n",
        "\n",
        "2. **Skewed distribution:**  \n",
        "   Let the outcomes $1, 2, 3$ have **double the probability** of $4, 5, 6$.  \n",
        "   Define the probabilities in the new distribution $Q$:\n",
        "   - For $i = 1, 2, 3$, let $Q(i) = 2p$.\n",
        "   - For $i = 4, 5, 6$, let $Q(i) = p$.\n",
        "\n",
        "   Since the sum of all probabilities must equal 1:\n",
        "$3(2p) + 3(p) = 1 \\quad \\Rightarrow \\quad 9p = 1 \\quad \\Rightarrow \\quad p = \\frac{1}{9}$\n",
        "\n",
        "   Therefore, the skewed distribution $Q$ is:\n",
        "$Q(i) = \\begin{cases} \\frac{2}{9}, & i \\in \\{1, 2, 3\\} \\\\ \\frac{1}{9}, & i \\in \\{4, 5, 6\\} \\end{cases}$\n",
        "\n",
        "#### **Step 2: Kullback-Leibler (KL) Divergence**\n",
        "\n",
        "The KL divergence between $P$ and $Q$ is defined as:\n",
        "$D_{\\text{KL}}(P || Q) = \\sum_{i=1}^{6} P(i) \\log \\left( \\frac{P(i)}{Q(i)} \\right)$\n",
        "\n",
        "For the fair dice distribution $P(i) = \\frac{1}{6}$, we compute the divergence separately for $i = 1, 2, 3$ and $i = 4, 5, 6$.\n",
        "\n",
        "#### **Step 3: Compute the KL divergence**\n",
        "\n",
        "1. **For $i = 1, 2, 3$:**\n",
        "$P(i) = \\frac{1}{6}, \\quad Q(i) = \\frac{2}{9}$\n",
        "   Contribution to KL divergence:\n",
        "$\\frac{1}{6} \\log \\left( \\frac{\\frac{1}{6}}{\\frac{2}{9}} \\right) = \\frac{1}{6} \\log \\left( \\frac{9}{12} \\right) = \\frac{1}{6} \\log \\left( \\frac{3}{4} \\right)$\n",
        "\n",
        "2. **For $i = 4, 5, 6$:**\n",
        "$P(i) = \\frac{1}{6}, \\quad Q(i) = \\frac{1}{9}$\n",
        "   Contribution to KL divergence:\n",
        "$\\frac{1}{6} \\log \\left( \\frac{\\frac{1}{6}}{\\frac{1}{9}} \\right) = \\frac{1}{6} \\log \\left( \\frac{9}{6} \\right) = \\frac{1}{6} \\log \\left( \\frac{3}{2} \\right)$\n",
        "\n",
        "#### **Step 4: Total KL divergence**\n",
        "\n",
        "The total KL divergence is the sum of the contributions from both groups of outcomes:\n",
        "$D_{\\text{KL}}(P || Q) = 3 \\cdot \\frac{1}{6} \\log \\left( \\frac{3}{4} \\right) + 3 \\cdot \\frac{1}{6} \\log \\left( \\frac{3}{2} \\right)$\n",
        "\n",
        "Simplify:\n",
        "$D_{\\text{KL}}(P || Q) = \\frac{1}{2} \\left( \\log \\left( \\frac{3}{4} \\right) + \\log \\left( \\frac{3}{2} \\right) \\right)$\n",
        "$= \\frac{1}{2} \\log \\left( \\frac{3}{4} \\cdot \\frac{3}{2} \\right) = \\frac{1}{2} \\log \\left( \\frac{9}{8} \\right)$\n",
        "\n",
        "#### **Final Answer**\n",
        "\n",
        "The Kullback-Leibler divergence between the two distributions is:\n",
        "$D_{\\text{KL}}(P || Q) = \\frac{1}{2} \\log \\left( \\frac{9}{8} \\right)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a1e00db-d9b6-460d-8530-f6e044d1fc6a",
      "metadata": {},
      "source": [
        "# Consider the coded caching scenario, where a transmitter serves $K = 3$ users via a broadcast shared-link (bottleneck-link), and where the transmitter has access to a library of $N = 6$ files (movies) A,B,C,D,E,F, each of size 1GigaByte (GB). Let each user have a cache of size $M = 2$ GBs.\n",
        "Describe:\n",
        "- The placement phase (what data goes into each user\u2019s cache)\n",
        "- The delivery phase (describe the sequence of XORs sent by the transmitter)\n",
        "- What is the total size of all the transmitted XORs together?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba48838-524d-47f2-8cea-853c65f388be",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#### **Given:**\n",
        "- **Number of users:** $K = 3$\n",
        "- **Library size:** $N = 6$ files (A, B, C, D, E, F), each 1 GB in size\n",
        "- **Cache size per user:** $M = 2$ GB\n",
        "- **Goal:** Efficient placement and delivery to minimize data sent over the bottleneck-link\n",
        "\n",
        "We will follow **Maddah-Ali and Niesen's Coded Caching Scheme** to describe the placement and delivery phases.\n",
        "\n",
        "#### **1. Placement Phase**\n",
        "\n",
        "The placement phase is done without knowledge of future user requests. Each file is divided into **subfiles** and cached according to the combinatorial scheme.\n",
        "\n",
        "Let each file (e.g., file A) be divided into **$\\binom{K}{t} = 3$** parts, where $t = \\frac{KM}{N} = 1$.  \n",
        "Thus, each file $W$ has **3 subfiles:**  \n",
        "$W = \\{ W_{1}, W_{2}, W_{3} \\}$\n",
        "\n",
        "For each user $i$, cache the subfiles corresponding to all subsets of $\\{1, 2, 3\\}$ that do **not** include $i$. Specifically:\n",
        "- **User 1** caches all subfiles $W_{2}$ and $W_{3}$ for every file $W$.\n",
        "- **User 2** caches all subfiles $W_{1}$ and $W_{3}$ for every file $W$.\n",
        "- **User 3** caches all subfiles $W_{1}$ and $W_{2}$ for every file $W$.\n",
        "\n",
        "Each user stores $\\frac{2}{3}$ of every file, leading to a total cache size of $M = 2$ GBs.\n",
        "\n",
        "#### **2. Delivery Phase**\n",
        "\n",
        "In this phase, each user requests a file. Assume the following requests:\n",
        "- **User 1:** File A\n",
        "- **User 2:** File B\n",
        "- **User 3:** File C\n",
        "\n",
        "Since each user already has $\\frac{2}{3}$ of every file, the transmitter only needs to deliver the remaining **missing subfiles** in an efficient way. The missing subfiles are:\n",
        "- User 1 needs $A_1$\n",
        "- User 2 needs $B_2$\n",
        "- User 3 needs $C_3$\n",
        "\n",
        "The transmitter exploits coded multicasting by sending **XORs** of missing subfiles that different users can decode using their cached data:\n",
        "1. **Send:** $A_1 \\oplus B_2 \\oplus C_3$\n",
        "\n",
        "Each user can decode their missing subfile:\n",
        "- **User 1:** Knows $B_2$ and $C_3$, can extract $A_1$.\n",
        "- **User 2:** Knows $A_1$ and $C_3$, can extract $B_2$.\n",
        "- **User 3:** Knows $A_1$ and $B_2$, can extract $C_3$.\n",
        "\n",
        "#### **3. Total Size of Transmitted XORs**\n",
        "\n",
        "Since each XOR combines **1/3 of a file** for each user, the total size of all transmitted XORs is:\n",
        "$\\text{Total transmitted size} = \\frac{1}{3} \\, \\text{GB}$\n",
        "\n",
        "Since only one XOR transmission is needed in this case, the total size is **1 GB**.\n",
        "\n",
        "#### **Summary**\n",
        "\n",
        "1. **Placement Phase:**  \n",
        "   - Each user caches $\\frac{2}{3}$ of every file, totaling 2 GB of data.\n",
        "\n",
        "2. **Delivery Phase:**  \n",
        "   - The transmitter sends $A_1 \\oplus B_2 \\oplus C_3$, which each user decodes using cached subfiles.\n",
        "\n",
        "3. **Total transmitted size:** **1 GB**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "839c3a9d-386e-4474-9d2b-5d85c3044534",
      "metadata": {},
      "source": [
        "# Consider the setting of horse-races with m= 4 horses, where the odds are even. Let the probability that the first horse wins be $p_1 = 1/2$, and the rest equal to $1/6$. Assume you bet 100 euros (starting bet).\n",
        "- To be optimal, how much should you bet on the fourth horse (horse number 4)?\n",
        "- What is the optimal doubling rate?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c038c28-247f-42f5-a275-0cdce8a0a1ac",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#### **Given:**\n",
        "- **Number of horses:** $m = 4$\n",
        "- **Odds:** Even (1-to-1 payout, win doubles the bet)\n",
        "- **Probabilities:**  \n",
        "  - $p_1 = \\frac{1}{2}$,  \n",
        "  - $p_2 = p_3 = p_4 = \\frac{1}{6}$\n",
        "\n",
        "- **Starting bet:** 100 euros  \n",
        "- **Goal:** Maximize the doubling rate $\\mathcal{D}$.\n",
        "\n",
        "#### **1. Optimal Betting Strategy**\n",
        "We apply **Kelly's Criterion**, which maximizes the long-term growth rate of capital. Let $f_k$ be the fraction of the capital bet on horse $k$, with the constraint:\n",
        "$\\sum_{k=1}^{4} f_k = 1$\n",
        "\n",
        "The optimal bets are determined by maximizing the **expected log wealth**:\n",
        "$\\mathcal{D} = \\sum_{k=1}^{4} p_k \\log(1 + 2 f_k)$\n",
        "\n",
        "#### **Step 1: Optimal Bet Fractions**\n",
        "The optimal fraction $f_k$ for horse $k$ is:\n",
        "$f_k = \\frac{p_k}{1 + p_k}$\n",
        "\n",
        "1. **For horse 1:**  \n",
        "   $p_1 = \\frac{1}{2}$\n",
        "$f_1 = \\frac{\\frac{1}{2}}{1 + \\frac{1}{2}} = \\frac{1}{3}$\n",
        "\n",
        "2. **For horse 2, 3, and 4:**  \n",
        "   $p_2 = p_3 = p_4 = \\frac{1}{6}$\n",
        "$f_2 = f_3 = f_4 = \\frac{\\frac{1}{6}}{1 + \\frac{1}{6}} = \\frac{1}{7}$\n",
        "\n",
        "#### **Step 2: Amount to Bet on Horse 4**\n",
        "- **Fraction to bet on horse 4:** $f_4 = \\frac{1}{7}$\n",
        "- **Total capital:** 100 euros  \n",
        "- **Bet on horse 4:**  \n",
        "$\\text{Bet amount} = f_4 \\times 100 = \\frac{1}{7} \\times 100 \\approx 14.29 \\, \\text{euros}$\n",
        "\n",
        "#### **Step 3: Optimal Doubling Rate**\n",
        "The optimal doubling rate $\\mathcal{D}$ is:\n",
        "$\\mathcal{D} = \\sum_{k=1}^{4} p_k \\log(1 + 2 f_k)$\n",
        "\n",
        "1. **For horse 1:**  \n",
        "$\\mathcal{D}_1 = \\frac{1}{2} \\log \\left(1 + 2 \\times \\frac{1}{3} \\right) = \\frac{1}{2} \\log \\left( \\frac{5}{3} \\right)$\n",
        "\n",
        "2. **For horses 2, 3, and 4:**  \n",
        "$\\mathcal{D}_2 = \\frac{1}{6} \\log \\left( 1 + 2 \\times \\frac{1}{7} \\right) = \\frac{1}{6} \\log \\left( \\frac{9}{7} \\right)$\n",
        "\n",
        "Thus, the total doubling rate is:\n",
        "$\\mathcal{D} = \\frac{1}{2} \\log \\left( \\frac{5}{3} \\right) + 3 \\cdot \\frac{1}{6} \\log \\left( \\frac{9}{7} \\right)$\n",
        "\n",
        "#### **Final Answers:**\n",
        "- **Bet on horse 4:** **14.29 euros**  \n",
        "- **Optimal doubling rate:**  \n",
        "$\\mathcal{D} = \\frac{1}{2} \\log \\left( \\frac{5}{3} \\right) + \\frac{1}{2} \\log \\left( \\frac{9}{7} \\right) \\approx 0.238 \\, \\text{bpcu}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18059d4-17dc-4c60-874f-6f0c9ab657a3",
      "metadata": {},
      "source": [
        "# What is the entropy of a zero-mean Real Gaussian Random Variable with variance $1$. How does the entropy change if the variance doubles, and how if the mean shifts to $3$?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a645e68-6a30-4993-8b45-268de8bc47fa",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#### **Entropy of a Real Gaussian Random Variable**\n",
        "For a **zero-mean** real Gaussian random variable $X$ with variance $\\sigma^2$, the entropy is given by:\n",
        "$H(X) = \\frac{1}{2} \\log \\left( 2 \\pi e \\sigma^2 \\right)$\n",
        "\n",
        "##### **Step 1: Entropy for $\\sigma^2 = 1$**\n",
        "When $X \\sim \\mathcal{N}(0, 1)$, $\\sigma^2 = 1$, the entropy is:\n",
        "$H(X) = \\frac{1}{2} \\log \\left( 2 \\pi e \\cdot 1 \\right) = \\frac{1}{2} \\log \\left( 2 \\pi e \\right)$\n",
        "\n",
        "##### **Step 2: If the variance doubles**  \n",
        "If the variance becomes $\\sigma^2 = 2$, the entropy is:\n",
        "$H(X) = \\frac{1}{2} \\log \\left( 2 \\pi e \\cdot 2 \\right) = \\frac{1}{2} \\log \\left( 4 \\pi e \\right)$\n",
        "\n",
        "Change in entropy:\n",
        "$\\Delta H = \\frac{1}{2} \\log \\left( \\frac{4 \\pi e}{2 \\pi e} \\right) = \\frac{1}{2} \\log(2)$\n",
        "\n",
        "The entropy increases by **$\\frac{1}{2} \\log(2) \\approx 0.347$ bits**.\n",
        "\n",
        "##### **Step 3: If the mean shifts to 3**  \n",
        "Entropy is invariant under mean shifts. If the mean shifts from $0$ to $3$, the entropy remains:\n",
        "$H(X) = \\frac{1}{2} \\log \\left( 2 \\pi e \\cdot \\sigma^2 \\right)$\n",
        "\n",
        "**Change in entropy:** **0 bits**.\n",
        "\n",
        "#### **Summary**\n",
        "- **Entropy of $\\mathcal{N}(0, 1)$:** $\\frac{1}{2} \\log(2 \\pi e) \\approx 1.418$ bits  \n",
        "- **If the variance doubles:** Entropy increases by $\\frac{1}{2} \\log(2) \\approx 0.347$ bits  \n",
        "- **If the mean shifts to 3:** Entropy does not change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9755fb62-8eb5-477e-94b5-6a9d6518b865",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.11.3",
      "language": "julia",
      "name": "julia-1.11"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}