{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58c6deb-23c8-43cb-9640-0f5c469ae247",
   "metadata": {},
   "source": [
    "# Channel polarization: A method for constructing capacity-achieving codes for symmetric binary-input memoryless channels\n",
    "\n",
    "#### Erdal ArÄ±kan, Senior Member, IEEE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec20ae-b6d2-41db-ab8b-b9617f5e9266",
   "metadata": {},
   "source": [
    "***Abstract*** â€” A method is proposed, called channel polarization,\n",
    "to construct code sequences that achieve the symmetric capacity $I(W)$ of any given binary-input discrete memoryless channel (BDMC) $W$. The symmetric capacity is the highest rate achievable\n",
    "subject to using the input letters of the channel with equal\n",
    "probability. Channel polarization refers to the fact that it is\n",
    "possible to synthesize, out of $N$ independent copies of a given B-DMC $W$, a second set of $N$ binary-input channels $\\{W_N^{(i)}: 1 \\leq i \\leq N\\}$ such that, as $N$ becomes large, the fraction of indices $i$ for which $I(W_N^{(i)})$  is near $1$ approaches $I(W)$ and the fraction for which $I(W_N^{(i)})$ is near $0$ approaches $1 âˆ’ I(W)$. The polarized channels $I(W_N^{(i)})$ are well-conditioned for channel coding: one need only send data at rate $1$ through those with capacity near $1$ and at rate $0$ through the remaining. Codes constructed on the basis of this idea are called polar codes. The paper proves that, given any B-DMC $W$ with $I(W) \\gt 0$ and any target rate $R \\le I(W)$, there exists a sequence of polar codes $\\{\\frak{C}_n, n \\geq 1 \\}$ such that $\\frak{C}_n$ has block-length $N = 2^n$, rate $\\geq R$, and\n",
    "probability of block error under successive cancellation decoding\n",
    "bounded as $P_e (N, R) \\leq O (N^{âˆ’\\frac{1}{4}})$ independently of the code rate.\n",
    "This performance is achievable by encoders and decoders with complexity $O(N \\log N)$ for each.\n",
    "\n",
    "***Index Terms*** â€” Capacity-achieving codes, channel capacity, channel polarization, Plotkin construction, polar codes, ReedMuller codes, successive cancellation decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdd876-54be-47cb-bf75-32abee6636c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Your abstract introduces a groundbreaking method called **channel polarization**, which is used to construct polar codes. These codes achieve the symmetric capacity $I(W)$ of binary-input discrete memoryless channels (B-DMCs). The main contributions and key highlights from the abstract include:\n",
    "\n",
    "1. **Channel Polarization**:\n",
    "   - Synthesizes $N$ independent copies of a B-DMC $W$ into $N$ binary-input channels $\\{W_N^{(i)} : 1 \\leq i \\leq N\\}$.\n",
    "   - As $N \\to \\infty$:\n",
    "     - A fraction of the polarized channels ($I(W_N^{(i)})$) approaches capacity ($\\sim 1$).\n",
    "     - The remaining channels have capacities near $0$, reflecting channel polarization.\n",
    "\n",
    "2. **Polar Codes**:\n",
    "   - Constructed by leveraging channel polarization.\n",
    "   - Achieve the symmetric capacity $I(W)$ for any B-DMC $W$ with $I(W) > 0$.\n",
    "\n",
    "3. **Code Properties**:\n",
    "   - Block length $N = 2^n$.\n",
    "   - Achieves rate $R \\leq I(W)$.\n",
    "   - Probability of block error under successive cancellation decoding satisfies:\n",
    "$P_e(N, R) \\leq O(N^{-\\frac{1}{4}})$\n",
    "   - Error performance is independent of the code rate.\n",
    "\n",
    "4. **Complexity**:\n",
    "   - Encoders and decoders have computational complexity $O(N \\log N)$, making them efficient for practical applications.\n",
    "\n",
    "5. **Keywords**:\n",
    "   - Capacity-achieving codes, channel polarization, polar codes, successive cancellation decoding, and related topics.\n",
    "\n",
    "This abstract succinctly captures the core innovation, theoretical guarantees, and practical feasibility of polar codes, emphasizing their capacity-achieving potential and computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9d8af-5877-4a9e-985e-f1be3e05dd44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d742ec-ca3d-4ded-b151-2ffd2cb83dac",
   "metadata": {},
   "source": [
    "\n",
    "Yes, polar coding can be represented using a **bipartite graph**, particularly when describing its encoding and decoding processes. This representation is helpful for understanding the flow of information and how bits are combined during encoding or decoded during successive cancellation decoding (SCD). Here's how the concept of a bipartite graph fits into polar coding:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Polar Coding and Graph Representation**\n",
    "Polar coding is based on the **Kronecker power** of a base matrix $F = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}$. This matrix defines the recursive structure of polar codes, which can be interpreted as a graph.\n",
    "\n",
    "#### Bipartite Graph in Polar Coding:\n",
    "- **Two Sets of Nodes**:\n",
    "  1. **Input Nodes**: Represent the input bits $u$, which include both information bits and frozen bits.\n",
    "  2. **Output Nodes**: Represent the encoded bits $x$, which are transmitted over the channel.\n",
    "- **Edges**:\n",
    "  - Each edge connects an input node to an output node, representing how input bits contribute to encoded bits during the encoding process.\n",
    "\n",
    "#### Example for $N = 4$:\n",
    "For $N = 4$, the generator matrix $G_4 = F^{\\otimes 2}$ is:\n",
    "$G_4 = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 1 & 1 & 0 & 0 \\\\ 1 & 0 & 1 & 0 \\\\ 1 & 1 & 1 & 1 \\end{bmatrix}.$\n",
    "This can be represented as a bipartite graph:\n",
    "\n",
    "```\n",
    "Input Nodes (u):    [u1, u2, u3, u4]\n",
    "Output Nodes (x):   [x1, x2, x3, x4]\n",
    "\n",
    "Edges:\n",
    "u1 â†’ x1, x2, x3, x4\n",
    "u2 â†’ x2, x4\n",
    "u3 â†’ x3, x4\n",
    "u4 â†’ x4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Graphical Interpretation of Encoding**\n",
    "\n",
    "In the bipartite graph:\n",
    "- **Input Nodes** ($u$):\n",
    "  - Contain both information bits and frozen bits.\n",
    "- **Output Nodes** ($x$):\n",
    "  - Represent encoded bits sent over the channel.\n",
    "- **Edge Connections**:\n",
    "  - An input node $u_i$ contributes to one or more output nodes $x_j$ based on the generator matrix $G_N$.\n",
    "\n",
    "This visualization provides insights into how the bits are combined and how redundancy is introduced for error correction.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Bipartite Graph in Decoding**\n",
    "\n",
    "During **successive cancellation decoding (SCD)**, the bipartite graph also plays a role:\n",
    "- The graph helps to visualize the dependencies between decoded bits.\n",
    "- Decoding proceeds sequentially, leveraging frozen bits and previously decoded bits to estimate the current bit.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Bipartite Graph Properties in Polar Coding**\n",
    "\n",
    "1. **No Cycles**:\n",
    "   - The polar coding bipartite graph has no cycles, as it is derived directly from the generator matrix, which defines a directed acyclic graph (DAG).\n",
    "   \n",
    "2. **Sparsity**:\n",
    "   - The bipartite graph for polar codes is sparse, especially for large block lengths $N$, since each input bit only contributes to specific output bits.\n",
    "\n",
    "3. **Hierarchical Structure**:\n",
    "   - The graph reflects the hierarchical combination of bits in the recursive construction of polar codes.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Applications of Bipartite Graph in Polar Codes**\n",
    "- **Encoding**:\n",
    "  - Visualizing the flow of information from input to output.\n",
    "- **Decoding**:\n",
    "  - Representing dependencies in SCD or other decoding algorithms.\n",
    "- **Error Analysis**:\n",
    "  - Studying how errors propagate through the graph.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "Polar coding uses a **bipartite graph** as an intuitive and practical way to represent the encoding and decoding processes. This graph is derived from the generator matrix $G_N$, with input and output nodes connected by edges that represent bit dependencies. While polar codes are not fundamentally based on bipartite graphs, this representation is highly useful for visualization, analysis, and algorithm development.\n",
    "\n",
    "Let me know if you'd like a code example to construct a polar code bipartite graph! ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0696ab-8bd3-403d-9dad-6910b067caec",
   "metadata": {},
   "source": [
    "### Polar Code Encoding and Generator Matrix $G_N$\n",
    "\n",
    "1. **Generator Matrix $G_N$:**\n",
    "   - Defined as:\n",
    "$G_N = F^{\\otimes n}, \\quad F = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}, \\quad N = 2^n.$\n",
    "   - $G_N$ recursively constructed using the Kronecker product.\n",
    "\n",
    "2. **Encoding Operation:**\n",
    "   - Encodes input $u_1^N$ into codeword $x_1^N$:\n",
    "$x_1^N = u_1^N G_N.$\n",
    "\n",
    "3. **Efficient Encoding ($O(N \\log N)$):**\n",
    "   - Direct multiplication ($O(N^2)$) is avoided by exploiting the recursive structure of $G_N$.\n",
    "   - Recursive divide-and-conquer reduces complexity to $O(N \\log N)$.\n",
    "\n",
    "4. **Relation to Fast Transform Methods:**\n",
    "   - $G_N$ resembles fast transforms like the Walsh-Hadamard Transform.\n",
    "   - Bit-indexing maps input/output bits via **bit-reversal permutations**.\n",
    "\n",
    "5. **Key Insight:**\n",
    "   - Efficient encoding leverages the recursive nature of $G_N$ and fast transform methods for practical implementation.\n",
    "\n",
    "Let me know if further clarification is needed! ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86ec8b-e72f-45e8-ac67-126dd300ae95",
   "metadata": {},
   "source": [
    "In the context of $\\mathcal{X}_D(N)$:\n",
    "\n",
    "1. **$\\mathcal{X}$**:\n",
    "   - Represents the **computational complexity**.\n",
    "   - It is used as a function to describe the number of operations required for a particular process, such as encoding or decoding.\n",
    "\n",
    "2. **$D$**:\n",
    "   - Refers to the **decoding process**.\n",
    "   - Specifically, it denotes **Successive Cancellation (SC) Decoding** in the context of polar codes.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of $\\mathcal{X}_D(N)$:\n",
    "- $\\mathcal{X}_D(N)$: The **worst-case time complexity** of the **SC decoding algorithm** for a polar code with block length $N = 2^n$.\n",
    "- It describes how the number of operations grows with $N$.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Idea:\n",
    "- The SC decoding process involves recursively splitting the problem into smaller subproblems using the hierarchical structure of $G_N = F^{\\otimes n}$.\n",
    "- For a block length $N$, the decoding complexity is:\n",
    "$\\mathcal{X}_D(N) = O(N \\log N).$\n",
    "\n",
    "This indicates that the decoding process is computationally efficient and scales logarithmically with the block length $N$. Let me know if you'd like more clarification! ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc5dee-120f-465f-a63e-26f178d7f4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
