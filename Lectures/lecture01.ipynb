{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f4f08a-0894-4905-9c34-54d2ad3918b6",
   "metadata": {},
   "source": [
    "### Entrory (in bits - amount of information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d42b592-67f0-4154-8ca7-e0958b46f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-(log2(p₁)) = 0.014499569695115089\n",
      "-(log2(p₂)) = 6.643856189774724\n"
     ]
    }
   ],
   "source": [
    "p₁ = 0.99; @show -log2(p₁);\n",
    "p₂ = 0.01; @show -log2(p₂);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999385e8-bf0d-4667-be9f-1fb72e28e948",
   "metadata": {},
   "source": [
    "### Joint Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17ebf4-f8a8-4c36-b2bf-96b2091e7298",
   "metadata": {},
   "source": [
    "$H(X,Y) = - E[log \\, p(X,Y)] = - \\sum\\limits_{x \\in \\mathcal{X}} \\sum\\limits_{y \\in \\mathcal{Y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77fe99-3d56-40fe-9c5c-3407a21ad5ea",
   "metadata": {},
   "source": [
    "### Proof of DPI using Marko Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d15ec-2fce-48cb-8b13-de112c450329",
   "metadata": {},
   "source": [
    "$P(X,Z|Y) \\overset{\\tiny\\text{(br)}}{=} \\frac{P(X,Y,Z)}{P(Y)} \\overset{\\tiny\\text{(br)}}{=} \\frac{P(Z|Y,X) \\, P(X,Y)}{P(Y)} \\overset{\\tiny\\text{(mc+br)}}{=} P(Z|Y) P(X|Y)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efb4b6-7e3b-4e31-aa26-6a5dd33e3cfb",
   "metadata": {},
   "source": [
    "#### Rules Coding\n",
    "- (br) => Bayes Rules\n",
    "- (cr) => Chain Rules\n",
    "- (cre) => Conditioning Reduces Entropy\n",
    "- (maxH) => Maximum Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c365388-1de3-49e2-ac40-bf5549b1ff96",
   "metadata": {},
   "source": [
    "$E[\\mathcal{L}(\\xi(X^n))]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81003c83-e391-461a-b389-4e9274e77847",
   "metadata": {},
   "source": [
    "### Shannon's Coding Theorem :\n",
    "\n",
    "#### Proof:\n",
    "\n",
    "- Let us build a random code  \n",
    "- We generate $ M $ code words $ X^n(1), X^n(2), \\dots, X^n(M) $.  \n",
    "  > According to $ P(X^n) = \\prod_{i=1}^n P(X_i), \\; X^n = (X_1, X_2, \\dots, X_n) $  \n",
    "- Assume that message $ i $ is transmitted ($ X^n(i) $ is transmitted).  \n",
    "- Decoder receives $ Y^n $.  \n",
    "- Decoder finds message $ i $ such that $ (X^n(i), Y^n) $ is jointly typical.  \n",
    "  > Let’s see what joint typicality (J.T.) means.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452f378e-d93b-45f8-a86e-bf6b555791dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmitted message index: 2\n",
      "Decoded message index: 1\n"
     ]
    }
   ],
   "source": [
    "using Random, Statistics, Distributions\n",
    "\n",
    "# Function to generate random codewords\n",
    "function generate_codewords(M, n, p_dist)\n",
    "    # Generate M codewords, each of length n, using distribution p_dist\n",
    "    return [rand(p_dist, n) for _ in 1:M]\n",
    "end\n",
    "\n",
    "# Function to simulate channel (add noise to transmitted codeword)\n",
    "function simulate_channel(Xn, noise_dist)\n",
    "    return Xn .+ rand(noise_dist, length(Xn))\n",
    "end\n",
    "\n",
    "# Joint typicality check (simplified for i.i.d. Gaussian noise)\n",
    "function is_jointly_typical(Xn, Yn, threshold)\n",
    "    n = length(Xn)\n",
    "    joint_average = mean(Xn .* Yn)\n",
    "    return abs(joint_average - mean(Xn) * mean(Yn)) < threshold\n",
    "end\n",
    "\n",
    "# Decoder: Find the message index based on joint typicality\n",
    "function decode(Yn, codebook, threshold)\n",
    "    for (i, Xn) in enumerate(codebook)\n",
    "        if is_jointly_typical(Xn, Yn, threshold)\n",
    "            return i  # Return the index of the jointly typical codeword\n",
    "        end\n",
    "    end\n",
    "    return nothing  # If no codeword is jointly typical, return nothing\n",
    "end\n",
    "\n",
    "# Parameters\n",
    "M = 4               # Number of codewords\n",
    "n = 10              # Length of each codeword\n",
    "p_dist = Bernoulli(0.5)  # Probability distribution for codewords\n",
    "noise_dist = Normal(0, 0.5)  # Noise distribution (Gaussian)\n",
    "threshold = 0.1     # Threshold for joint typicality\n",
    "\n",
    "# Generate random codewords\n",
    "codebook = generate_codewords(M, n, p_dist)\n",
    "\n",
    "# Transmit message i\n",
    "i_transmitted = 2\n",
    "Xn_transmitted = codebook[i_transmitted]\n",
    "Yn_received = simulate_channel(Xn_transmitted, noise_dist)\n",
    "\n",
    "# Decode the received message\n",
    "i_decoded = decode(Yn_received, codebook, threshold)\n",
    "\n",
    "# Print results\n",
    "println(\"Transmitted message index: \", i_transmitted)\n",
    "println(\"Decoded message index: \", i_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658a5dc-95ea-440b-9a49-785a122fddcd",
   "metadata": {},
   "source": [
    "This image appears to describe a calculation related to joint typicality in the context of information theory. Specifically, it deals with the sizes of the typical sets and the probability of joint typicality.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "\t1.\tTypical Sets:\n",
    "\t•\t￼ and ￼ are the sizes of the ￼-typical sets for ￼ and ￼, respectively.\n",
    "\t•\tHere, ￼.\n",
    "\t•\t￼ is the size of the joint ￼-typical set for the pair ￼.\n",
    "\t•\tHere, ￼.\n",
    "\t2.\tJoint Probability:\n",
    "\t•\tThe probability of the pair ￼ belonging to the joint ￼-typical set is bounded by:\n",
    "￼\n",
    "\t•\tSubstituting the given sizes:\n",
    "￼\n",
    "\n",
    "Context:\n",
    "\n",
    "This calculation is likely part of a discussion on random coding in information theory, where:\n",
    "\t•\t￼ and ￼ are sequences (e.g., codewords and received sequences).\n",
    "\t•\tTypical sets are used to analyze the performance of communication systems, particularly error probabilities and decoding regions.\n",
    "\t•\tJoint typicality ensures that the decoder selects the correct message.\n",
    "\n",
    "If you’d like more clarification or a detailed explanation of how this ties into a broader context (e.g., Shannon’s theorem, random coding argument), let me know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
